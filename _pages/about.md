---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently an associate professor in [John Hopcroft Center](https://jhc.sjtu.edu.cn/) of Shanghai Jiao Tong University.

My research interests include AR/VR, avatars/characters, 3D animations, HCI, and computer graphics. Previously, I was an Associate Research Scientist in AR/VR at Disney Research Los Angeles. I received the B.Sc. degree in communication and information engineering from Purdue/UESTC in 2010 and the Ph.D. degree in computer graphics from the University College London (UCL) in 2015. I has served as Associate Editor of the International Journal of Human Computer Studies, and a regular member of IEEE virtual reality program committees.

I am looking for self-motivated PhD, master and undergraduate students to join my research group. My E-mail address is **whitneypanye@sjtu.edu.cn**. Please contact me if you are interested.


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CAVW 2018</div><img src='images/Empowerment_and_embodiment_for_collaborative_mixed_reality_systems.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Empowerment and embodiment for collaborative mixed reality systems](https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.1838)

**Ye Pan**, David Sinclair, Kenny Mitchell

- We present several mixed‚Äêreality‚Äêbased remote collaboration settings by using consumer head‚Äêmounted displays. We investigated how two people are able to work together in these settings. We found that the person in the AR system will be regarded as the ‚Äúleader‚Äù (i.e., they provide a greater contribution to the collaboration), whereas no similar ‚Äúleader‚Äù emerges in augmented reality (AR)‚Äêto‚ÄêAR and AR‚Äêto‚ÄêVRBody settings. We also found that these special patterns of leadership only emerged for 3D interactions and not for 2D interactions. Results about the participants' experience of leadership, collaboration, embodiment, presence, and copresence shed further light on these findings.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">PloS one 2017</div><img src='images/The_impact_of_self-avatars_on_trust_and_collaboration_in_shared_virtual_environments.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[The impact of self-avatars on trust and collaboration in shared virtual environments](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189078)

**Ye Pan**, Anthony Steed

- A self-avatar is known to have a potentially significant impact on the user‚Äôs experience of the immersive content but it can also affect how users interact with each other in a shared virtual environment (SVE). We implemented an SVE for a consumer virtual reality system where each user‚Äôs body could be represented by a jointed self-avatar that was dynamically controlled by head and hand controllers. We investigated the impact of a self-avatar on collaborative outcomes such as completion time and trust formation during competitive and cooperative tasks. We used two different embodiment levels: no self-avatar and self-avatar, and compared these to an in-person face to face version of the tasks. We found that participants could finish the task more quickly when they cooperated than when they competed, for both the self-avatar condition and the face to face condition, but not for the no self-avatar condition. In terms of trust formation, both the self-avatar condition and the face to face condition led to higher scores than the no self-avatar condition; however, collaboration style had no significant effect on trust built between partners. The results are further evidence of the importance of a self-avatar representation in immersive virtual reality.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">VR 2016</div><img src='images/The_impact_of_a_self-avatar_on_cognitive_load_in_immersive_virtual_reality.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[The impact of a self-avatar on cognitive load in immersive virtual reality](https://ieeexplore.ieee.org/abstract/document/7504689)

Anthony Steed, **Ye Pan**, Fiona Zisch, William Steptoe

- The use of a self-avatar inside an immersive virtual reality system has been shown to have important effects on presence, interaction and perception of space. Based on studies from linguistics and cognition, in this paper we demonstrate that a self-avatar may aid the participant's cognitive processes while immersed in a virtual reality system. In our study participants were asked to memorise pairs of letters, perform a spatial rotation exercise and then recall the pairs of letters. In a between-subject factor they either had an avatar or not, and in a within-subject factor they were instructed to keep their hands still or not. We found that participants who both had an avatar and were allowed to move their hands had significantly higher letter pair recall. There was no significant difference between the other three conditions. Further analysis showed that participants who were allowed to move their hands, but could not see the self-avatar, usually didn't move their hands or stopped moving their hands after a short while. We argue that an active self-avatar may alleviate the mental load of doing the spatial rotation exercise and thus improve letter recall. The results are further evidence of the importance of an appropriate self-avatar representation in immersive virtual reality.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TVCG 2016</div><img src='images/An_in_the_wild_experiment_on_presence_and_embodiment_using_consumer_virtual_reality_equipment.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An ‚Äòin the wild‚Äôexperiment on presence and embodiment using consumer virtual reality equipment](https://ieeexplore.ieee.org/abstract/document/7383331)

Anthony Steed, Sebastian Frlston, Maria Murcia Lopez, Jason Drummond, **Ye Pan**, David Swapp

- Consumer virtual reality systems are now becoming widely available. We report on a study on presence and embodiment within virtual reality that was conducted `in the wild', in that data was collected from devices owned by consumers in uncontrolled settings, not in a traditional laboratory setting. Users of Samsung Gear VR and Google Cardboard devices were invited by web pages and email invitation to download and run an app that presented a scenario where the participant would sit in a bar watching a singer. Each participant saw one of eight variations of the scenario: with or without a self-avatar; singer inviting the participant to tap along or not; singer looking at the participant or not. Despite the uncontrolled situation of the experiment, results from an in-app questionnaire showed tentative evidence that a self-avatar had a positive effect on self-report of presence and embodiment, and that the singer inviting the participant to tap along had a negative effect on self-report of embodiment. We discuss the limitations of the study and the platforms, and the potential for future open virtual reality experiments.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Frontiers in Robotics and AI 2016</div><img src='images/A_comparison_of_avatar_video_and_robot_mediated_interaction_on_users_trust_in_expertise.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A comparison of avatar-, Video-, and robot-Mediated interaction on Users‚Äô Trust in expertise](https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2016.00012/full)

**Ye Pan**, Anthony Steed

- Communication technologies are becoming increasingly diverse in form and functionality. A central concern is the ability to detect whether others are trustworthy. Judgments of trustworthiness rely, in part, on assessments of non-verbal cues, which are affected by media representations. In this research, we compared trust formation on three media representations. We presented 24 participants with advisors represented by two of the three alternate formats: video, avatar, or robot. Unknown to the participants, one was an expert, and the other was a non-expert. We observed participants‚Äô advice-seeking behavior under risk as an indicator of their trust in the advisor. We found that most participants preferred seeking advice from the expert, but we also found a tendency for seeking robot or video advice. Avatar advice, in contrast, was more rarely sought. Users‚Äô self-reports support these findings. These results suggest that when users make trust assessments, the physical presence of the robot representation might compensate for the lack of identity cues.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJHCS 2016</div><img src='images/Effects_of_3D_perspective_on_head_gaze_estimation_with_a_multiview_autostereoscopic_display.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Effects of 3D perspective on head gaze estimation with a multiview autostereoscopic display](https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.1638)

**Ye Pan**, Anthony Steed

- Head gaze, or the orientation of the head, is a very important attentional cue in face to face conversation. Some subtleties of the gaze can be lost in common teleconferencing systems, because a single perspective warps spatial characteristics. A recent random hole display is a potentially interesting display for group conversation, as it allows multiple stereo viewers in arbitrary locations, without the restriction of conventional autostereoscopic displays on viewing positions. We represented a remote person as an avatar on a random hole display. We evaluated this system by measuring the ability of multiple observers with different horizontal and vertical viewing angles to accurately and simultaneously judge which targets the avatar is gazing at. We compared three perspective conditions: a conventional 2D view, a monoscopic perspective-correct view, and a stereoscopic perspective-correct views. In the latter two conditions, the random hole display shows three and six views simultaneously. Although the random hole display does not provide high quality view, because it has to distribute display pixels among multiple viewers, the different views are easily distinguished. Results suggest the combined presence of perspective-correct and stereoscopic cues significantly improved the effectiveness with which observers were able to assess the avatar‚Äôs head gaze direction. This motivates the need for stereo in future multiview displays.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CAVW 2015</div><img src='images/Symmetric_telepresence_using_robotic_humanoid_surrogates.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Symmetric telepresence using robotic humanoid surrogates](https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.1638)

Arjun Nagendran, Anthony Steed, Brian Kelly, **Ye Pan**

- Telepresence involves the use of virtual reality technology to facilitate apparent physical participation in distant events, including potentially performing tasks, while creating a sense of being in that location. Traditionally, such systems are asymmetric in nature where only one side (participant) is ‚Äúteleported‚Äù to the remote location. In this manuscript, the authors explore the possibility of symmetric three-dimensional telepresence where both sides (participants) are ‚Äúteleported‚Äù simultaneously to each other's location; the overarching concept of symmetric telepresence in virtual environments is extended to telepresence robots in physical environments. Two identical physical humanoid robots located in UK and the USA serve as surrogates while performing a transcontinental shared collaborative task. The actions of these surrogate robots are driven by capturing the intent of the participants controlling them in either location. Participants could communicate verbally but could not see the other person or the remote location while performing the task. The effectiveness of gesturing along with other observations during this preliminary experiment is presented. Results reveal that the symmetric robotic telepresence allowed participants to use and understand gestures in cases where they would otherwise have to describe their actions verbally. 
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint 2015</div><img src='images/An_empirical_study_on_display_ad_impression_viewability_measurements.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An empirical study on display ad impression viewability measurements](https://arxiv.org/abs/1505.05788)

Weinan Zhang, **Ye Pan**, Tianxiong Zhou, Jun Wang

- Display advertising normally charges advertisers for every single ad impression. Specifically, if an ad in a webpage has been loaded in the browser, an ad impression is counted. However, due to the position and size of the ad slot, lots of ads are actually not viewed but still measured as impressions and charged. These fraud ad impressions indeed undermine the efficacy of display advertising. A perfect ad impression viewability measurement should match what the user has really viewed with a short memory. In this paper, we conduct extensive investigations on display ad impression viewability measurements on dimensions of ad creative displayed pixel percentage and exposure time to find which measurement provides the most accurate ad impression counting. The empirical results show that the most accurate measurement counts one ad impression if more than 75% of the ad creative pixels have been exposed for at least 2 continuous seconds.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Presence 2015</div><img src='images/A_surround_video_capture_and_presentation_system_for_preservation_of_eye_gaze_in_teleconferencing_applications.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A surround video capture and presentation system for preservation of eye-gaze in teleconferencing applications](https://ieeexplore.ieee.org/abstract/document/7226422)

**Ye Pan**, Oyewole Oyekoya, Anthony Steed

- We propose a new video conferencing system that uses an array of cameras to capture a remote user and then show the video of that person on a spherical display. This telepresence system has two key advantages: (i) it can capture a near-correct image for any potential observer viewing direction because the cameras surround the user horizontally; and (ii) with view-dependent graphical representation on the spherical display, it is possible to tell where the remote user is looking from any viewpoint, whereas flat displays are visible only from the front. As a result, the display can more faithfully represent the gaze of the remote user. We evaluate this system by measuring the ability of observers to accurately judge which targets the actor is gazing at in two experiments. Results from the first experiment demonstrate the effectiveness of the camera array and spherical display system, in that it allows observers at multiple observing positions to accurately tell at which targets the remote user is looking. The second experiment further compared a spherical display with a planar display and provided detailed reasons for the improvement of our system in conveying gaze. We found two linear models for predicting the distortion introduced by misalignment of capturing cameras and the observer's viewing angles in video conferencing systems. Those models might be able to enable a correction for this distortion in future display configurations.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGCHI 2014</div><img src='images/A_gaze_preserving_situated_multiview_telepresence_system.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A gaze-preserving situated multiview telepresence system](https://dl.acm.org/doi/abs/10.1145/2556288.2557320)

**Ye Pan**, Anthony Steed

- Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGCHI 2014</div><img src='images/Comparing_flat_and_spherical_displays_in_a_trust_scenario_in_avatar_mediated_interaction.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction](https://dl.acm.org/doi/abs/10.1145/2556288.2557276)

**Ye Pan**, William Steptoe, Anthony Steed

- We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. By monitoring advice seeking behavior, our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between expert and non-expert advice than if they observe the avatar face-on. We then introduce a novel spherical display and a ray-traced rendering technique that can display an avatar that can be seen correctly from any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non-verbal cues, particularly gaze direction, since it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate expert advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiments demonstrate how trust can be altered depending on how one views the avatar.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">3DTV 2012</div><img src='images/Preserving_gaze_direction_in_teleconferencing_using_a_camera_array_and_a_spherical_display.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Preserving gaze direction in teleconferencing using a camera array and a spherical display](https://ieeexplore.ieee.org/abstract/document/6365433)

**Ye Pan**, Anthony Steed

- The movement of human gaze is very important in face to face conversation. Some of the quality of that movement is lost in videoconferencing because the participants look at a single planar image of the remote person. We use an array of cameras to capture a remote user, and then display video of that person on a spherical display. We compare the spherical display to a face to face setting and a planar display. We demonstrate the effectiveness of the camera array and spherical display system in that it allows observers to accurately judge where the remote user is placing their gaze. 
</div>
</div>


# üìñ Educations
- *2011.09 - 2015.02*, [University College London](https://www.ucl.ac.uk/), PhD.
- *2010.09 - 2011.09*, [University College London](https://www.ucl.ac.uk/), Master. 
- *2006.09 - 2010.07*, [University of Electronic Science and technology](https://www.uestc.edu.cn/), Bachelor. 

# üíª Work Experience
- *2019.11 - Present*, [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/), Associate Professor.
- *2017.09 - 2019.10*, [University College London](https://www.ucl.ac.uk/), Associate Research Scientist.
- *2015.02 - 2017.09*, [University College London](https://www.ucl.ac.uk/), Postdoc.
